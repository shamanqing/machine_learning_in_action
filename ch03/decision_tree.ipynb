{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_shannon_ent(dataset):\n",
    "    item_num = len(dataset)\n",
    "    labels = {}\n",
    "    for item in dataset:\n",
    "        label = item[-1]\n",
    "        labels[label] = labels.get(label, 0) + 1\n",
    "    shannon_ent = 0.0\n",
    "    for key in labels:\n",
    "        prob = labels[key] / item_num\n",
    "        shannon_ent -= prob  * np.log2(prob)\n",
    "    \n",
    "    return shannon_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    data_set = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    \n",
    "    labels = ['no surfacing', 'flippers']\n",
    "    return data_set, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataset, axis, value):\n",
    "    features = []\n",
    "    for item in dataset:\n",
    "        if item[axis] == value:\n",
    "            vec = item[:axis]\n",
    "            vec.extend(item[axis+1:])\n",
    "            features.append(vec)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature(dataset):\n",
    "    num_features = len(dataset[0]) - 1\n",
    "    \n",
    "    ent_gain = 0.0\n",
    "    best_i = 0\n",
    "    for i in range(num_features):\n",
    "        feature_i = [x[i] for x in dataset]\n",
    "        unique_val = set(feature_i)\n",
    "        \n",
    "        ent_val = 0.0\n",
    "        for val in unique_val:\n",
    "            subset = split_dataset(dataset, i, val)\n",
    "            prob = len(subset) / len(dataset)\n",
    "            ent_val += prob * calc_shannon_ent(subset)\n",
    "        \n",
    "        new_ent_gain = calc_shannon_ent(dataset) - ent_val\n",
    "        \n",
    "#         print(i, new_ent_gain)\n",
    "        if new_ent_gain > ent_gain:\n",
    "            ent_gain = new_ent_gain\n",
    "            best_i = i\n",
    "#     print(best_i)\n",
    "    return best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_max_label(dataset):\n",
    "    label_cnt ={}\n",
    "    for item in dataset:\n",
    "        label_cnt[item[-1]] = label_cnt.get(item[-1], 0) + 1\n",
    "    \n",
    "    return max(label_cnt, key=label_cnt.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, labels):\n",
    "    class_list = [x[-1] for x in dataset]\n",
    "    \n",
    "    #标签相同时，返回标签\n",
    "    unique_class = set(class_list)\n",
    "    if len(unique_class) <= 1:\n",
    "        return class_list[0]\n",
    "    \n",
    "    #特征为空集时，返回最大标签\n",
    "    if len(dataset[0]) <= 1:\n",
    "        return choose_max_label(dataset)\n",
    "    \n",
    "    best_i  = choose_best_feature(dataset)\n",
    "    best_label = labels[best_i]\n",
    "    \n",
    "#     print(best_label)\n",
    "    my_tree = {best_label:{}}\n",
    "    \n",
    "    feature_val = [x[best_i] for x in dataset]\n",
    "    unique_val = set(feature_val)\n",
    "    \n",
    "    for val in unique_val:\n",
    "        sublabels = labels[:best_i] + labels[best_i+1:]\n",
    "        my_tree[best_label][val] = create_tree(split_dataset(dataset, best_i, val), sublabels)\n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(input_tree, feature_labels, test_vec):\n",
    "    first_str = list(input_tree.keys())[0]\n",
    "    second_dict = input_tree[first_str]\n",
    "#     print(first_str)\n",
    "#     print(feature_labels)\n",
    "    feat_index = feature_labels.index(first_str)\n",
    "    \n",
    "    for key in second_dict:\n",
    "        if test_vec[feat_index] == key:\n",
    "            if type(second_dict[key]).__name__ == 'dict':\n",
    "                class_label = classify(second_dict[key], feature_labels, test_vec)\n",
    "            else:\n",
    "                class_label = second_dict[key]\n",
    "    \n",
    "    return class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no surfacing', 'flippers']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data, labels = create_dataset()\n",
    "tree = create_tree(my_data, labels)\n",
    "classify(tree, labels, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = open('lenses.txt', 'r')\n",
    "dataset = [line.strip().split('\\t') for line in fr.readlines()]\n",
    "labels = ['age', 'prescript', 'astigmatic', 'tearRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = create_tree(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tearRate': {'normal': {'astigmatic': {'no': {'age': {'young': 'soft',\n",
       "      'presbyopic': {'prescript': {'hyper': 'soft', 'myope': 'no lenses'}},\n",
       "      'pre': 'soft'}},\n",
       "    'yes': {'prescript': {'hyper': {'age': {'young': 'hard',\n",
       "        'presbyopic': 'no lenses',\n",
       "        'pre': 'no lenses'}},\n",
       "      'myope': 'hard'}}}},\n",
       "  'reduced': 'no lenses'}}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
